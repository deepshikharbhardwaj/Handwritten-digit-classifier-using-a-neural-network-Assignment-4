# -*- coding: utf-8 -*-
"""M20MA004_Assigment_4_Neural_Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14h1pebB7XuQOyMgDhNor4rJTGS6rek2G
"""

import numpy as np
!pip install mnist tensorflow
import mnist
import matplotlib.pyplot as plt
from keras.models import Sequential 
from keras.layers import Dense
from keras.utils import to_categorical

#loading dataset
train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

#Normalise pixel values from range [0, 255] to [0, 1]
train_images = train_images/255 
test_images = test_images/255  

#Flatten the image from 2D (28X28) to 1D [784X1]
train_images = train_images.reshape(-1,784)
test_images = test_images.reshape(-1,784)

print(train_images.shape) #60000 rows and 784 columns
print(test_images.shape) #10000 rows and 784 columns

#Build Model
model = Sequential()
model.add(Dense(128, activation = 'relu',  input_dim = 784))
model.add(Dense(10, activation = 'softmax'))

#Compile Model
model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics = ['accuracy'])


#Train data with different batch sizes 
#Train Model with Batch Size 32

#print(model.fit(train_images, to_categorical(train_labels), epochs = 5, batch_size = 32))
history = model.fit(train_images, to_categorical(train_labels), epochs = 10, batch_size = 32)
plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#Evaluate Test images
model.evaluate(test_images, to_categorical(test_labels))
print("Evaluating the model for test data")

print(model.evaluate(test_images, to_categorical(test_labels)))

#prediction on first 30 data images
y_pred = model.predict(test_images[:30])
#print(y_pred)
print(np.argmax(y_pred, axis = 1))
print(test_labels[:30])

first_image = test_images[28]  #Randomly chosen 28th image
first_image = np.array(first_image)
pixel = first_image.reshape(28,28)
plt.imshow(pixel)
plt.axis("off")
plt.show()

#Experimenting with different Batches (Taking batch size = 64)

#Adding import statements again as code was not recognizing np, mnist from first cell.
import numpy as np
!pip install mnist tensorflow
import mnist
import matplotlib.pyplot as plt
from keras.models import Sequential 
from keras.layers import Dense
from keras.utils import to_categorical

#loading dataset
train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

#Normalise pixel values from range [0, 255] to [0, 1]
train_images = train_images/255 
test_images = test_images/255  

#Flatten the image from 2D (28X28) to 1D [784X1]
train_images = train_images.reshape(-1,784)
test_images = test_images.reshape(-1,784)

print(train_images.shape) #60000 rows and 784 columns
print(test_images.shape) #10000 rows and 784 columns

#Build Model
model = Sequential()
model.add(Dense(128, activation = 'relu',  input_dim = 784))
model.add(Dense(10, activation = 'softmax'))

#Compile Model
model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics = ['accuracy'])

#Train data with different batch sizes 
#Train Model with Batch Size 64
model.fit(train_images, to_categorical(train_labels), epochs = 5, batch_size = 64)

#Evaluate Test images
model.evaluate(test_images, to_categorical(test_labels))

#prediction on first 30 data images
y_pred = model.predict(test_images[:30])
#print(y_pred)
print(np.argmax(y_pred, axis = 1))
print(test_labels[:30])

first_image = test_images[17]  #Randomly chosen 17th image
first_image = np.array(first_image)
pixel = first_image.reshape(28,28)
plt.imshow(pixel)
plt.axis("off")
plt.show()

#Image Pixel inversion
train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

train_images = np.abs(255 - train_images )
test_images = np.abs(255 - test_images  )


#Normalise pixel values from range [0, 255] to [0, 1]
train_images = train_images/255
test_images = test_images/255  

#Flatten the image from 2D (28X28) to 1D [784X1]
train_images = train_images.reshape(-1,784)
test_images = test_images.reshape(-1,784)

print(train_images.shape) #60000 rows and 784 columns
print(test_images.shape) #10000 rows and 784 columns

#Build Model
model = Sequential()
model.add(Dense(64, activation = 'relu',  input_dim = 784))
model.add(Dense(64, activation = 'relu')) #middle
model.add(Dense(10, activation = 'softmax'))

#Compile Model
model.compile(optimizer = 'Adam' , loss = 'categorical_crossentropy', metrics = ['accuracy'])

#Train data with different batch sizes 
#Train Model with Batch Size 32
model.fit(train_images, to_categorical(train_labels), epochs = 10, batch_size = 32)

#Evaluate Test images
print("Evaluating the model for test data")
x = to_categorical(test_labels)

print(model.evaluate(test_images, x))
#print(model.evaluate(test_images,tf.keras.utils.to_categorical(test_labels)))
print(train_images.shape) #60000 rows and 784 columns
print(test_images.shape) #10000 rows and 784 columns

#prediction on first 30 data images
y_pred = model.predict(test_images[:30])
#print(y_pred)
print(np.argmax(y_pred, axis = 1))
print(test_labels[:30])
for i in range(0,5):
  first_image = test_images[i]  
  first_image = np.array(first_image)
  pixel = first_image.reshape(28,28)
  plt.imshow(pixel)
  plt.axis("off")
  plt.show()

import numpy as np
!pip install mnist tensorflow
import mnist
import matplotlib.pyplot as plt
from keras.models import Sequential 
from keras.layers import Dense
from keras.utils import to_categorical

#Normal Pixels
#Image Pixel inversion
train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels() 

#Image Pixel inversion
itrain_images = mnist.train_images()
itrain_labels = mnist.train_labels()
itest_images = mnist.test_images()
itest_labels = mnist.test_labels()

itrain_images = np.abs(255 - itrain_images )
itest_images = np.abs(255 - itest_images  )

#Final Train Images
final_train_images=[]
for i in range(train_images.shape[0]):
  if i%2 == 0:
    final_train_images.append(train_images[i])
  else:
    final_train_images.append(itrain_images[i])
#print(a)
final_train_images = np.array(final_train_images)

#Final Train Labels
f_train_labels=[]
for i in range(train_labels.shape[0]):
  if i%2 == 0:
    f_train_labels.append(train_labels[i])
  else:
    f_train_labels.append(itrain_labels[i])
f_train_labels = np.array(f_train_labels)

#Normalise pixel values from range [0, 255] to [0, 1]

final_train_images = final_train_images/255 
test_images = test_images/255  

#Flatten the image from 2D (28X28) to 1D [784X1]
final_train_images = final_train_images.reshape(-1,784)
test_images = test_images.reshape(-1,784)
#f_train_labels = f_train_labels.reshape(-1,60000)

print(final_train_images.shape) #60000 rows and 784 columns
print(test_images.shape) #10000 rows and 784 columns

#Build Model
model = Sequential()
model.add(Dense(128, activation = 'relu',  input_dim = 784))
model.add(Dense(10, activation = 'softmax'))

#Compile Model
model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics = ['accuracy'])

#Output the Mixed Training images
y_pred = model.predict(final_train_images[:30])
#print(y_pred)
print(np.argmax(y_pred, axis = 1))
print(test_labels[:30])
for i in range(6):
  image = final_train_images[i+19]  #Randomly chosen images
  image = np.array(image)
  pixel = image.reshape(28,28)
  plt.imshow(pixel)
  plt.axis("off")
  plt.show()

#Train data with different batch sizes 
#Train Model with Batch Size 32

#print(model.fit(train_images, to_categorical(train_labels), epochs = 5, batch_size = 32))
history = model.fit(final_train_images, to_categorical(f_train_labels), epochs = 5, batch_size = 32)
plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#Evaluate Test images
model.evaluate(test_images, to_categorical(test_labels))
print("Evaluating the model for test data")
print(model.evaluate(test_images, to_categorical(test_labels)))

#prediction on first 30 data images
y_pred = model.predict(test_images[:30])
#print(y_pred)
print(np.argmax(y_pred, axis = 1))
print(test_labels[:30])
for i in range(6):
  first_image = test_images[i+19]  #Randomly chosen images
  first_image = np.array(first_image)
  pixel = first_image.reshape(28,28)
  plt.imshow(pixel)
  plt.axis("off")
  plt.show()
